{
	"name": "Azure Spark SQL",
	"properties": {
		"nbformat": 4,
		"nbformat_minor": 2,
		"bigDataPool": {
			"referenceName": "sparkpoolprac84",
			"type": "BigDataPoolReference"
		},
		"sessionProperties": {
			"driverMemory": "28g",
			"driverCores": 4,
			"executorMemory": "28g",
			"executorCores": 4,
			"numExecutors": 2,
			"conf": {
				"spark.dynamicAllocation.enabled": "false",
				"spark.dynamicAllocation.minExecutors": "2",
				"spark.dynamicAllocation.maxExecutors": "2",
				"spark.autotune.trackingId": "f2256d44-b5ae-4462-899a-ca8c3991f6c1"
			}
		},
		"metadata": {
			"saveOutput": true,
			"enableDebugMode": false,
			"kernelspec": {
				"name": "synapse_pyspark",
				"display_name": "Synapse PySpark"
			},
			"language_info": {
				"name": "sql"
			},
			"a365ComputeOptions": {
				"id": "/subscriptions/acdf152f-3867-4db8-9da5-81dfde654c21/resourceGroups/rg-dev-revenue-practice/providers/Microsoft.Synapse/workspaces/ws-azsynapse1984/bigDataPools/sparkpoolprac84",
				"name": "sparkpoolprac84",
				"type": "Spark",
				"endpoint": "https://ws-azsynapse1984.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/sparkpoolprac84",
				"auth": {
					"type": "AAD",
					"authResource": "https://dev.azuresynapse.net"
				},
				"sparkVersion": "3.4",
				"nodeCount": 3,
				"cores": 8,
				"memory": 56,
				"automaticScaleJobs": false
			},
			"sessionKeepAliveTimeout": 30
		},
		"cells": [
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"The Spark SQL syntax is similar to T-SQL; hence, you will not have difficulty in using this \r\n",
					"as your primary language. However, keep in mind that Spark SQL does not support all the \r\n",
					"features available in T-SQL.\r\n",
					"\r\n",
					"The following script will create a managed table from Spark. The table is created in the \r\n",
					"Synapse warehouse folder in your primary storage account. The table will be synchronized \r\n",
					"and available in Synapse SQL pools."
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"collapsed": false
				},
				"source": [
					"drop table if exists cities"
				],
				"execution_count": 32
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"collapsed": false
				},
				"source": [
					"CREATE TABLE cities\r\n",
					"  (name STRING, population INT)\r\n",
					"  USING PARQUET"
				],
				"execution_count": 33
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"collapsed": false
				},
				"source": [
					"INSERT INTO cities VALUES ('Seattle', 730400), \r\n",
					"('San Francisco', 881549), ('Beijing', 21540000), \r\n",
					"('Bangalore', 10540000)"
				],
				"execution_count": 34
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"When you run any script in Spark SQL, you can see the Spark job running in the output \r\n",
					"window. Once the job is complete, the Status field will be updated to Succeeded.\r\n",
					"\r\n",
					"Next, you can perform the SELECT operation on this table to validate whether the data \r\n",
					"has been inserted"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"collapsed": false
				},
				"source": [
					"SELECT * FROM cities\r\n",
					"ORDER BY name"
				],
				"execution_count": 35
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"##### Creating an unmanaged Spark table"
				]
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"An unmanaged Spark table is also known as an external table. You can create external \r\n",
					"tables from Spark by using Spark SQL. We need to provide a value for the LOCATION\r\n",
					"parameter, which defines the path where the Spark table must be created."
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"collapsed": false
				},
				"source": [
					"drop table if exists cities"
				],
				"execution_count": 37
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"collapsed": false
				},
				"source": [
					"CREATE TABLE cities\r\n",
					"  (name STRING, population INT)\r\n",
					"  USING PARQUET\r\n",
					"  LOCATION '/datalake/cities'\r\n",
					"  OPTIONS ('compression'='snappy')"
				],
				"execution_count": 38
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"collapsed": false
				},
				"source": [
					"INSERT INTO cities VALUES ('Seattle', 730400), \r\n",
					"('San Francisco', 881549), ('Beijing', 21540000), \r\n",
					"('Bangalore', 10540000)"
				],
				"execution_count": 39
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"collapsed": false
				},
				"source": [
					"SELECT * FROM cities\r\n",
					"ORDER BY name"
				],
				"execution_count": 40
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					""
				],
				"execution_count": null
			}
		]
	}
}